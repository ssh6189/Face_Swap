{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dlib' has no attribute 'get_frontal_face_detector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-42c76df7037f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# initialize face detector and shape predictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'shape_predictor_68_face_landmarks.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dlib' has no attribute 'get_frontal_face_detector'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "scaler = 0.3\n",
    "\n",
    "# initialize face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture('./girl.mp4')\n",
    "# load overlay image\n",
    "overlay = cv2.imread('./ryan_transparent.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# overlay function\n",
    "def overlay_transparent(background_img, img_to_overlnpmay_t, x, y, overlay_size=None):\n",
    "    bg_img = background_img.copy()\n",
    "    # convert 3 channels to 4 channels\n",
    "    if bg_img.shape[2] == 3:\n",
    "        bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    if overlay_size is not None:\n",
    "        img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "        \n",
    "    b, g, r, a = cv2.split(img_to_overlay_t)\n",
    "    \n",
    "    mask = cv2.medianBlur(a, 5)\n",
    "    \n",
    "    h, w, _ = img_to_overlay_t.shape\n",
    "    \n",
    "    roi = bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)]\n",
    "    \n",
    "    img1_bg = cv2.bitwise_and(roi.copy(), roi.copy(), mask=cv2.bitwise_not(mask))\n",
    "    img2_fg = cv2.bitwise_and(img_to_overlay_t, img_to_overlay_t, mask=mask)\n",
    "    \n",
    "    bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)] = cv2.add(img1_bg, img2_fg)\n",
    "    \n",
    "    # convert 4 channels to 4 channels\n",
    "    bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "    return bg_img\n",
    "\n",
    "face_roi = []\n",
    "face_sizes = []\n",
    "\n",
    "# loop\n",
    "while True:\n",
    "    # read frame buffer from video\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # resize frame\n",
    "    img = cv2.resize(img, (int(img.shape[1] * scaler), int(img.shape[0] * scaler)))\n",
    "    ori = img.copy()\n",
    "    \n",
    "    # find faces\n",
    "    if len(face_roi) == 0:\n",
    "        faces = detector(img, 1)\n",
    "    else:\n",
    "        roi_img = img[face_roi[0]:face_roi[1], face_roi[2]:face_roi[3]]\n",
    "        # cv2.imshow('roi', roi_img)\n",
    "        faces = detector(roi_img)\n",
    "        \n",
    "    # no faces\n",
    "    if len(faces) == 0:\n",
    "        print('no faces!')\n",
    "        \n",
    "    # find facial landmarks\n",
    "    for face in faces:\n",
    "        if len(face_roi) == 0:\n",
    "            dlib_shape = predictor(img, face)\n",
    "            shape_2d = np.array([[p.x, p.y] for p in dlib_shape.parts()])\n",
    "        else:\n",
    "            dlib_shape = predictor(roi_img, face)\n",
    "            shape_2d = np.array([[p.x + face_roi[2], p.y + face_roi[0]] for p in dlib_shape.parts()])\n",
    "            \n",
    "        for s in shape_2d:\n",
    "            cv2.circle(img, center=tuple(s), radius=1, color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "            \n",
    "        # compute face center\\\n",
    "        center_x, center_y = np.mean(shape_2d, axis=0).astype(np.int)\n",
    "        \n",
    "        # compute face boundaries\n",
    "        min_coords = np.min(shape_2d, axis=0)\n",
    "        max_coords = np.max(shape_2d, axis=0)\n",
    "        \n",
    "        # draw min, max coords\n",
    "        cv2.circle(img, center=tuple(min_coords), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "        cv2.circle(img, center=tuple(max_coords), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "        \n",
    "        # compute face size\n",
    "        face_size = max(max_coords - min_coords)\n",
    "        face_sizes.append(face_size)\n",
    "        \n",
    "        if len(face_sizes) > 10:\n",
    "            del face_sizes[0]\n",
    "        mean_face_size = int(np.mean(face_sizes) * 1.8)\n",
    "        \n",
    "        # compute face roi\n",
    "        face_roi = np.array([int(min_coords[1] - face_size / 2), int(max_coords[1] + face_size / 2), int(min_coords[0] - face_size / 2), int(max_coords[0] + face_size / 2)])\n",
    "        face_roi = np.clip(face_roi, 0, 10000)\n",
    "        \n",
    "        # draw overlay on face\n",
    "        result = overlay_transparent(ori, overlay, center_x + 8, center_y - 25, overlay_size=(mean_face_size, mean_face_size))\n",
    "        \n",
    "        # visualize\n",
    "        cv2.imshow('original', ori)\n",
    "        cv2.imshow('facial landmarks', img)\n",
    "        cv2.imshow('result', result)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c8cf3fa4b122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import camera\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class FaceRecog():\n",
    "    def __init__(self):\n",
    "        # Using OpenCV to capture from device 0. If you have trouble capturing\n",
    "        # from a webcam, comment the line below out and use a video file\n",
    "        # instead.\n",
    "        self.camera = camera.VideoCamera()\n",
    "\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "\n",
    "        # Load sample pictures and learn how to recognize it.\n",
    "        dirname = 'knowns'\n",
    "        files = os.listdir(dirname)\n",
    "        for filename in files:\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            if ext == '.jpg':\n",
    "                self.known_face_names.append(name)\n",
    "                pathname = os.path.join(dirname, filename)\n",
    "                img = face_recognition.load_image_file(pathname)\n",
    "                face_encoding = face_recognition.face_encodings(img)[0]\n",
    "                self.known_face_encodings.append(face_encoding)\n",
    "\n",
    "        # Initialize some variables\n",
    "        self.face_locations = []\n",
    "        self.face_encodings = []\n",
    "        self.face_names = []\n",
    "        self.process_this_frame = True\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.camera\n",
    "\n",
    "    def get_frame(self):\n",
    "        # Grab a single frame of video\n",
    "        frame = self.camera.get_frame()\n",
    "\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "        # Only process every other frame of video to save time\n",
    "        if self.process_this_frame:\n",
    "            # Find all the faces and face encodings in the current frame of video\n",
    "            self.face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            self.face_encodings = face_recognition.face_encodings(rgb_small_frame, self.face_locations)\n",
    "\n",
    "            self.face_names = []\n",
    "            for face_encoding in self.face_encodings:\n",
    "                # See if the face is a match for the known face(s)\n",
    "                distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "                min_value = min(distances)\n",
    "\n",
    "                # tolerance: How much distance between faces to consider it a match. Lower is more strict.\n",
    "                # 0.6 is typical best performance.\n",
    "                name = \"Unknown\"\n",
    "                if min_value < 0.6:\n",
    "                    index = np.argmin(distances)\n",
    "                    name = self.known_face_names[index]\n",
    "\n",
    "                self.face_names.append(name)\n",
    "\n",
    "        self.process_this_frame = not self.process_this_frame\n",
    "\n",
    "        # Display the results\n",
    "        for (top, right, bottom, left), name in zip(self.face_locations, self.face_names):\n",
    "            # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def get_jpg_bytes(self):\n",
    "        frame = self.get_frame()\n",
    "        # We are using Motion JPEG, but OpenCV defaults to capture raw images,\n",
    "        # so we must encode it into JPEG in order to correctly display the\n",
    "        # video stream.\n",
    "        ret, jpg = cv2.imencode('.jpg', frame)\n",
    "        return jpg.tobytes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
